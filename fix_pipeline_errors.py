#!/usr/bin/env python3
"""
Comprehensive Pipeline Error Fix and Validation Script

This script identifies and fixes all potential errors in the Arabic voice cloning
training pipeline to ensure it runs correctly with the user's ChatML data format.
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Any

class PipelineErrorFixer:
    """Comprehensive error detection and fixing for the training pipeline."""
    
    def __init__(self, project_root: str):
        """Initialize the error fixer."""
        self.project_root = Path(project_root)
        self.core_files = [
            "arabic_voice_cloning_lora_config.py",
            "arabic_voice_cloning_dataset.py", 
            "arabic_voice_cloning_training_collator.py",
            "arabic_voice_cloning_loss_function.py",
            "arabic_voice_cloning_distributed_trainer.py",
            "train_arabic_voice_cloning.py",
            "validation_and_testing.py",
            "lora_merge_and_checkpoint_manager.py"
        ]
        self.fixes_applied = []
    
    def check_and_fix_imports(self) -> List[str]:
        """Check and fix import issues in all core files."""
        import_fixes = []
        
        for file_name in self.core_files:
            file_path = self.project_root / file_name
            if not file_path.exists():
                continue
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Fix 1: Ensure Tuple is imported where needed
            if 'Tuple[' in content and 'from typing import' in content:
                # Check if Tuple is already in the import
                typing_import_line = None
                for line_num, line in enumerate(content.split('\n')):
                    if line.strip().startswith('from typing import'):
                        typing_import_line = line_num
                        break
                
                if typing_import_line is not None:
                    lines = content.split('\n')
                    import_line = lines[typing_import_line]
                    if 'Tuple' not in import_line:
                        # Add Tuple to the import
                        import_parts = import_line.split('import')[1].strip().split(',')
                        import_parts = [part.strip() for part in import_parts]
                        if 'Tuple' not in import_parts:
                            import_parts.append('Tuple')
                            new_import = f"from typing import {', '.join(sorted(import_parts))}"
                            lines[typing_import_line] = new_import
                            content = '\n'.join(lines)
                            import_fixes.append(f"Added Tuple import to {file_name}")
            
            # Fix 2: Fix device_map None issue
            if 'device_map=None' in content:
                content = content.replace('device_map=None', 'device_map="cpu"')
                import_fixes.append(f"Fixed device_map=None in {file_name}")
            
            # Fix 3: Ensure proper Optional imports for type hints
            if 'Optional[' in content and 'Optional' not in content.split('from typing import')[1].split('\n')[0] if 'from typing import' in content else False:
                # Add Optional to typing imports
                for line_num, line in enumerate(content.split('\n')):
                    if line.strip().startswith('from typing import'):
                        import_parts = line.split('import')[1].strip().split(',')
                        import_parts = [part.strip() for part in import_parts]
                        if 'Optional' not in import_parts:
                            import_parts.append('Optional')
                            lines = content.split('\n')
                            lines[line_num] = f"from typing import {', '.join(sorted(import_parts))}"
                            content = '\n'.join(lines)
                            import_fixes.append(f"Added Optional import to {file_name}")
                        break
            
            # Fix 4: Fix any missing Union imports
            if 'Union[' in content and 'Union' not in content.split('from typing import')[1].split('\n')[0] if 'from typing import' in content else False:
                for line_num, line in enumerate(content.split('\n')):
                    if line.strip().startswith('from typing import'):
                        import_parts = line.split('import')[1].strip().split(',')
                        import_parts = [part.strip() for part in import_parts]
                        if 'Union' not in import_parts:
                            import_parts.append('Union')
                            lines = content.split('\n')
                            lines[line_num] = f"from typing import {', '.join(sorted(import_parts))}"
                            content = '\n'.join(lines)
                            import_fixes.append(f"Added Union import to {file_name}")
                        break
            
            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
        return import_fixes
    
    def check_and_fix_function_signatures(self) -> List[str]:
        """Check and fix function signature issues."""
        signature_fixes = []
        
        for file_name in self.core_files:
            file_path = self.project_root / file_name
            if not file_path.exists():
                continue
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Fix 1: Ensure proper return type annotations
            # Look for functions that return tuples but don't have Tuple annotation
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if 'def ' in line and 'return ' in content[content.find(line):]:
                    # Check if function returns tuple but doesn't have Tuple annotation
                    if '->' not in line and i + 1 < len(lines):
                        # Look ahead for return statements
                        func_content = []
                        j = i + 1
                        indent_level = len(line) - len(line.lstrip())
                        while j < len(lines) and (lines[j].strip() == '' or len(lines[j]) - len(lines[j].lstrip()) > indent_level):
                            func_content.append(lines[j])
                            j += 1
                        
                        # Check if it returns a tuple
                        func_text = '\n'.join(func_content)
                        if 'return (' in func_text or 'return model,' in func_text:
                            # This function likely returns a tuple, check if it needs annotation
                            if 'create_higgs_audio_lora_model' in line:
                                if '-> Tuple[' not in line:
                                    # Add return type annotation
                                    if ')' in line and ':' in line:
                                        line_parts = line.split('):')
                                        if len(line_parts) >= 2:
                                            lines[i] = f"{line_parts[0]}) -> Tuple[PeftModel, HiggsAudioConfig, HiggsAudioLoRATrainingConfig]:{':'.join(line_parts[1:])}"
                                            signature_fixes.append(f"Added return type annotation to create_higgs_audio_lora_model in {file_name}")
            
            content = '\n'.join(lines)
            
            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
        
        return signature_fixes
    
    def check_and_fix_dataclass_issues(self) -> List[str]:
        """Check and fix dataclass-related issues."""
        dataclass_fixes = []
        
        for file_name in self.core_files:
            file_path = self.project_root / file_name
            if not file_path.exists():
                continue
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Fix 1: Ensure dataclass imports
            if '@dataclass' in content and 'from dataclasses import' not in content:
                # Add dataclass import at the top
                lines = content.split('\n')
                import_line_idx = -1
                for i, line in enumerate(lines):
                    if line.startswith('import ') or line.startswith('from '):
                        import_line_idx = i
                
                if import_line_idx >= 0:
                    lines.insert(import_line_idx + 1, 'from dataclasses import dataclass, field')
                    content = '\n'.join(lines)
                    dataclass_fixes.append(f"Added dataclass import to {file_name}")
            
            # Fix 2: Ensure field imports for default_factory
            if 'field(default_factory=' in content and 'field' not in content.split('from dataclasses import')[1].split('\n')[0] if 'from dataclasses import' in content else False:
                for line_num, line in enumerate(content.split('\n')):
                    if 'from dataclasses import' in line and 'field' not in line:
                        lines = content.split('\n')
                        import_parts = line.split('import')[1].strip().split(',')
                        import_parts = [part.strip() for part in import_parts]
                        if 'field' not in import_parts:
                            import_parts.append('field')
                            lines[line_num] = f"from dataclasses import {', '.join(import_parts)}"
                            content = '\n'.join(lines)
                            dataclass_fixes.append(f"Added field import to {file_name}")
                        break
            
            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
        
        return dataclass_fixes
    
    def check_and_fix_variable_name_issues(self) -> List[str]:
        """Check and fix variable naming and scope issues."""
        variable_fixes = []
        
        for file_name in self.core_files:
            file_path = self.project_root / file_name
            if not file_path.exists():
                continue
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Fix 1: Check for undefined variables that might be missing
            # This is a simple check - in a real scenario we'd need AST parsing
            
            # Fix 2: Ensure proper exception handling
            if 'except Exception as e:' in content:
                # Make sure logger is available for exception logging
                if 'logger.error' in content and 'from loguru import logger' not in content and 'import logging' not in content:
                    lines = content.split('\n')
                    # Add loguru import
                    for i, line in enumerate(lines):
                        if line.startswith('import ') or line.startswith('from '):
                            lines.insert(i, 'from loguru import logger')
                            content = '\n'.join(lines)
                            variable_fixes.append(f"Added logger import to {file_name}")
                            break
            
            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
        
        return variable_fixes
    
    def check_and_fix_path_issues(self) -> List[str]:
        """Check and fix path-related issues."""
        path_fixes = []
        
        for file_name in self.core_files:
            file_path = self.project_root / file_name
            if not file_path.exists():
                continue
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Fix 1: Ensure Path imports where needed
            if 'Path(' in content and 'from pathlib import Path' not in content:
                lines = content.split('\n')
                # Add Path import
                for i, line in enumerate(lines):
                    if line.startswith('import ') or line.startswith('from '):
                        lines.insert(i, 'from pathlib import Path')
                        content = '\n'.join(lines)
                        path_fixes.append(f"Added Path import to {file_name}")
                        break
            
            # Fix 2: Check for audio_base_path references that should be removed
            if 'audio_base_path' in content and 'removed' not in content:
                # This might be a leftover reference that should be cleaned up
                lines = content.split('\n')
                new_lines = []
                for line in lines:
                    if 'audio_base_path' in line and ('config' in line or 'parameter' in line):
                        # Comment out the line
                        new_lines.append(f"# {line.strip()}  # Removed: using direct paths from ChatML")
                        path_fixes.append(f"Commented out audio_base_path reference in {file_name}")
                    else:
                        new_lines.append(line)
                content = '\n'.join(new_lines)
            
            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
        
        return path_fixes
    
    def generate_requirements_fix(self) -> str:
        """Generate a requirements.txt file with all necessary dependencies."""
        requirements = [
            "torch>=2.0.0",
            "transformers>=4.30.0",
            "peft>=0.4.0",
            "accelerate>=0.21.0",
            "librosa>=0.10.0",
            "soundfile>=0.12.0",
            "torchaudio>=2.0.0",
            "wandb>=0.15.0",
            "loguru>=0.7.0",
            "psutil>=5.9.0",
            "numpy>=1.21.0",
            "pandas>=1.3.0",
            "PyYAML>=6.0",
            "tqdm>=4.64.0",
            "safetensors>=0.3.0"
        ]
        
        req_file = self.project_root / "requirements_training.txt"
        with open(req_file, 'w') as f:
            f.write('\n'.join(requirements))
        
        return f"Generated requirements_training.txt with all necessary dependencies"
    
    def run_comprehensive_fix(self) -> Dict[str, List[str]]:
        """Run all fixes and return a summary."""
        print("ðŸ”§ Running comprehensive pipeline error fixing...")
        
        fixes = {
            "imports": self.check_and_fix_imports(),
            "signatures": self.check_and_fix_function_signatures(),
            "dataclasses": self.check_and_fix_dataclass_issues(),
            "variables": self.check_and_fix_variable_name_issues(),
            "paths": self.check_and_fix_path_issues(),
            "requirements": [self.generate_requirements_fix()]
        }
        
        return fixes
    
    def generate_fix_report(self, fixes: Dict[str, List[str]]) -> str:
        """Generate a comprehensive fix report."""
        report = []
        report.append("# Pipeline Error Fix Report")
        report.append("=" * 50)
        
        total_fixes = sum(len(fix_list) for fix_list in fixes.values())
        report.append(f"Total fixes applied: {total_fixes}")
        report.append("")
        
        for category, fix_list in fixes.items():
            if fix_list:
                report.append(f"## {category.title()} Fixes ({len(fix_list)})")
                for fix in fix_list:
                    report.append(f"- {fix}")
                report.append("")
        
        report.append("## Next Steps")
        report.append("1. Install dependencies: `pip install -r requirements_training.txt`")
        report.append("2. Run validation: `python validate_complete_pipeline.py --chatml_file your_data.json`")
        report.append("3. Start training: `python train_arabic_voice_cloning.py --data_path your_data.json --output_dir ./outputs`")
        
        return "\n".join(report)


def main():
    """Main function to run the pipeline error fixer."""
    print("ðŸš€ Arabic Voice Cloning Pipeline Error Fixer")
    print("=" * 60)
    
    project_root = Path(__file__).parent
    fixer = PipelineErrorFixer(str(project_root))
    
    # Run comprehensive fixes
    fixes = fixer.run_comprehensive_fix()
    
    # Generate and save report
    report = fixer.generate_fix_report(fixes)
    report_file = project_root / "PIPELINE_FIX_REPORT.md"
    with open(report_file, 'w') as f:
        f.write(report)
    
    print(report)
    print(f"\nðŸ“„ Detailed report saved to: {report_file}")
    
    # Summary
    total_fixes = sum(len(fix_list) for fix_list in fixes.values())
    if total_fixes > 0:
        print(f"\nâœ… Applied {total_fixes} fixes to the pipeline")
        print("ðŸŽ¯ Pipeline should now be ready for training!")
    else:
        print("\nâœ… No issues found - pipeline is already in good shape!")
    
    return total_fixes > 0


if __name__ == "__main__":
    main()